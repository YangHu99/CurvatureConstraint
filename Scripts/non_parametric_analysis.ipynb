{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GvZxM40nWoq-"},"outputs":[],"source":["\"\"\"\n","Author: Yang Hu\n","1. This file gives a script to constrain cosmological parameters (H0, Omega0, Omegak, MB, etc.)\n","using strong gravitational lenses (lenses) and type Ia supernovae (SNe) with non-parametric analysis.\n","2. We use baryon accoustic oscillation data (BAO) to obtain an interpolated curve for Hubble parameter Hz via\n","Gaussian Process (GP). GP is carried out using george package.\n","3. For lenses, we use simulated LSST data. For SNe, we use simulated Roman data. For BAO, we use simulated DESI data.\n","4. Constraints on parameters are obtained via Markov Chain Monte Carlo (MCMC) using emcee package.\n","\"\"\""]},{"cell_type":"code","source":["!pip install -U emcee\n","!pip install corner\n","!pip install astropy\n","!pip install george"],"metadata":{"id":"DorRMkuYWqi6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2KKn0pRBWoq_"},"outputs":[],"source":["\"\"\"\n","standard imports for data analysis; astropy.cosmology to compute astrophysical quantities with ease; george to run\n","GP and emcee to run MCMC\n","\"\"\"\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.integrate import simps\n","from scipy.optimize import minimize\n","\n","import george\n","from george import kernels\n","import emcee\n","import corner\n","from astropy.cosmology import FlatLambdaCDM, FlatwCDM, LambdaCDM, wCDM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8jmEfwyWoq_"},"outputs":[],"source":["\"\"\"\n","Load original data. Please check that the relevant data files are named and stored in the way the code below\n","specified.\n","\"\"\"\n","\n","#load&rename lenses data\n","data1 = pd.read_csv(\"Data/zlens_zsource_LSSTLike.txt\", delimiter=' ', header=None)\n","zlens = np.array(data1[0])\n","zsource = np.array(data1[1])\n","ddt_err = np.array(data1[2])\n","\n","#load&rename SNe data\n","data2 = pd.read_csv(\"Data/lcparam_WFIRST_G10.txt\", delimiter=' ', skiprows=1, header=None)\n","data3 = pd.read_csv(\"Data/syscov_WFIRST.txt\", delimiter=' ', skiprows=0, header=None)\n","name = \"Roman\"\n","zcmb = np.array(data2[1])\n","#for a measure of the uncertainty of SNe measurement, we need the covariance matrix in the following way\n","mb_err = np.array(data2[5])\n","sys_err = np.array(data3)\n","D_stat = np.diag(mb_err**2)\n","C_sys = sys_err.reshape((len(data2), len(data2)))\n","C = D_stat + C_sys\n","C_inv = np.linalg.inv(C)\n","\n","#load&rename BAO data\n","data4 = pd.read_csv(\"Data/DESI_HZ_error.txt\", delimiter=' ', skiprows=1, header=None)\n","zBAO = np.array(data4[0])\n","sigHz = np.array(data4[1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PU_5_gm5WorA"},"outputs":[],"source":["\"\"\"\n","Sometimes we want more simulated data for lenses. Here we provide a way to genearate more LSST-like data.\n","The number of lensing events in the original LSST-like data is 310, an estimate of expected observed number\n","of events in LSST's 10-year survey baseline.\n","\"\"\"\n","\n","#decide whether to generate data and uncertainty for lenses and whether to use them\n","generate_data = False\n","generate_uncertainty = False\n","save_data = False\n","use_data = True\n","\n","\n","#first entry for number is the total number of data points we want, second entry is the number of original data\n","real_number = 1000\n","number = real_number-310\n","#choose a python random seed for this random process involved\n","seed_no = 20\n","\n","if generate_uncertainty:\n","    np.random.seed(seed_no)\n","    pu = np.random.uniform(0.06, 0.1, size=len(data1[0]))\n","\n","if generate_data:\n","    np.random.seed(seed_no)\n","    rand_number = np.random.randint(0, 309, size=number)\n","\n","if save_data:\n","    data_temp = np.array(data1)\n","    data_temp[:, 2]=pu\n","    for i in rand_number:\n","        data_temp = np.append(data_temp, [data_temp[i]], axis=0)\n","    df = pd.DataFrame(np.concatenate(([data_temp[:, 0]], [data_temp[:, 1]], [data_temp[:, 2]])).T)\n","    df.to_csv(r'Data/zlens_zsource_%sLSSTLike_%s.csv' % ((number+310), seed_no), index=False)\n","\n","if use_data:\n","    data_new = pd.read_csv(\"Data/zlens_zsource_%sLSSTLike_%s.csv\" % ((number+310), seed_no), skiprows=1, header=None)\n","    zlens = np.array(data_new[0])\n","    zsource = np.array(data_new[1])\n","    ddt_err = np.array(data_new[2])*np.sqrt(310/real_number)\n","else:\n","    zlens = data1[0]\n","    zsource = data1[1]\n","    ddt_err = data1[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-DQXJbiWorA"},"outputs":[],"source":["\"\"\"\n","We need to choose a mock universe model to generate the \"true value\" of parameters which are then\n","used to compute the difference between true and measured (simulated) values which in turn are used to get\n","the constraints of parameters.\n","\"\"\"\n","\n","#set mock cosmology\n","#common parameters we are interested in are Hubble's constant H0, matter density Om0, curvature density Ok0,\n","#equation of state parameter w and absolute magnitude of SNe Ia MB.\n","\n","H0_mock, Om0_mock, Ok0_mock, w_mock, MB_mock = 72, 0.3, 0.00, -1, -19.2\n","cosmo_mock = wCDM(H0=H0_mock, Om0=Om0_mock, Ode0=1.-Om0_mock-Ok0_mock, w0=w_mock)\n","\n","#compute mock time-delay distance for lenses\n","dd_mock = cosmo_mock.angular_diameter_distance(z=zlens).value\n","ds_mock = cosmo_mock.angular_diameter_distance(z=zsource).value\n","dds_mock = cosmo_mock.angular_diameter_distance_z1z2(z1=zlens, z2=zsource).value\n","ddt_mock = (1. + zlens) * dd_mock * ds_mock / dds_mock\n","\n","#compute mock luminosity distance for SNe\n","dl_mock = cosmo_mock.luminosity_distance(z=zcmb).value\n","mb_mock = 5*np.log10(dl_mock)+25+MB_mock\n","\n","#compute mock Hz from BAO data\n","Hz_mock = cosmo_mock.H(z=zBAO).value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkvLBLTgWorA"},"outputs":[],"source":["\"\"\"\n","GP interpolate Hz from BAO data using george package\n","\"\"\"\n","\n","#function to get GP interpolation\n","def get_gp_interp(zBAO, Hz_mock, sigHz):\n","    \"\"\"\n","    Compute the GP interpolation with the error covariance matrix\n","    TO DO: Marginalise over kernel hyperparameters\n","    zBAO: array of z from BAO\n","    Hz_mock: array of Hz from BAO\n","    sigHz: array of uncertainty of Hz\n","    \"\"\"\n","    #the 2 optical numerical values of hyperparameters are obtained via MCMC in a seperate script:\n","    #\"HzGP_constraint.ipynb\"\n","    #you can also find the values in \"amp_ls_corner_32x8000.png\"\n","    gp = george.GP(10.163*np.var(Hz_mock)*kernels.ExpSquaredKernel(1.924),\n","               mean=np.mean(Hz_mock), white_noise=None)\n","    Hz = Hz_mock\n","    Hz_err = sigHz\n","    #define the redshift region for predicting the GP fit\n","    z_step = np.linspace(0., max(zBAO), 4000)\n","    gp.compute(zBAO, Hz_err)\n","    Hz_gp = gp.predict(Hz, z_step, return_cov=False)\n","    return z_step, Hz_gp\n","\n","z_step, Hz_gp = get_gp_interp(zBAO, Hz_mock, sigHz)\n","#normalise the E(z)\n","Ez_gp = Hz_gp/Hz_gp[0]\n","#this is the normalised Hz interpolation curve"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJTDB_Y6WorA"},"outputs":[],"source":["\"\"\"\n","We want to get cosmological distances in likelihood function in a non-parametric way.\n","\"\"\"\n","\n","c = 299792.458 #in km/s\n","\n","#function to get time-delay distance in a non-parametric way\n","def get_model_indep_dist_ddt(zl, zs, z_step, Ez_gp, h0, ok):\n","    \"\"\"\n","    Doesn't account for errors in the GP fit as of now\n","    zl: float of z at lenses\n","    zs: float of z at source to integrate till\n","    z_step: float, the baseline step for integrating\n","    Ez_gp: array of normalised Hubble parameter from GP interpolation\n","    h0: float, a value of Hubble's constant\n","    ok: float, a value of curvature density parameter\n","    \"\"\"\n","    cond_l = z_step <= zl\n","    cond_s = z_step <= zs\n","    Ez_gp_l = Ez_gp[cond_l]\n","    Ez_gp_s = Ez_gp[cond_s]\n","    dh = c/h0\n","\n","    int_comov_l = simps(1/Ez_gp_l, z_step[cond_l])\n","    int_comov_s = simps(1/Ez_gp_s, z_step[cond_s])\n","\n","    if ok < 0.:\n","        dm_l = dh/np.sqrt(abs(ok))*np.sin(np.sqrt(abs(ok))*int_comov_l)\n","        dm_s = dh/np.sqrt(abs(ok))*np.sin(np.sqrt(abs(ok))*int_comov_s)\n","    elif ok == 0.:\n","        dm_l = dh*int_comov_l\n","        dm_s = dh*int_comov_s\n","    elif ok > 0.:\n","        dm_l = dh/np.sqrt(abs(ok))*np.sinh(np.sqrt(abs(ok))*int_comov_l)\n","        dm_s = dh/np.sqrt(abs(ok))*np.sinh(np.sqrt(abs(ok))*int_comov_s)\n","\n","    da_l = dm_l/(1+zl)\n","    da_s = dm_s/(1+zs)\n","    da_ls = (1/(1+zs) *\n","             (dm_s * np.sqrt(1 + ok * (dm_l / dh)**2) - dm_l * np.sqrt(1 + ok * (dm_s / dh)**2)))\n","\n","    ddt = (1 + zl) * da_l * da_s / da_ls\n","    return ddt\n","\n","#function to get luminosity distance in a non-parametric way\n","def get_model_indep_dist_dl(z, z_step, Ez_gp, h0, ok):\n","    \"\"\"\n","    Doesn't account for errors in the GP fit as of now\n","    z: float of z from SNe\n","    z_step: float, the baseline step for integrating\n","    Ez_gp: array of normalised Hubble parameter from GP interpolation\n","    h0: float, a value of Hubble's constant\n","    ok: float, a value of curvature density parameter\n","    \"\"\"\n","    cond = z_step <= z\n","    Ez_gp = Ez_gp[cond]\n","    if ok < 0.:\n","        int_comov = simps(1/Ez_gp, z_step[cond])\n","        comov_curv = np.sqrt(abs(ok)) * int_comov\n","        dl_int = c*np.sin(comov_curv) * (1+z) / (np.sqrt(abs(ok)))\n","    elif ok > 0.:\n","        int_comov = simps(1/Ez_gp, z_step[cond])\n","        comov_curv = np.sqrt(abs(ok)) * int_comov\n","        dl_int = c*np.sinh(comov_curv) * (1+z) / (np.sqrt(abs(ok)))\n","    elif ok == 0.:\n","        int_comov = simps(1/Ez_gp, z_step[cond])\n","        comov_curv = int_comov\n","        dl_int = c*comov_curv * (1+z)\n","    dl_int /= h0\n","    return dl_int"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBr2OMdkWorB"},"outputs":[],"source":["\"\"\"\n","This cell defines the loss function of MCMC\n","Constraints are obtained by MCMC and here we define the relevant prior and likelihood functions\n","\"\"\"\n","\n","use_Lens = True\n","use_SNe = True\n","\n","max_likelihood_test = True\n","\n","#use uniform priors for all parameters\n","def log_prior(theta):\n","    \"\"\"\n","    theta: list of floats, folded cosmological parameters.\n","    \"\"\"\n","    if use_SNe:\n","        h0, ok, Mb = theta\n","        if 0. <= h0 <= 150. and -2. <= ok <= 2. and -25. <= Mb <= -15.:\n","            return 0.0\n","        else:\n","            return -np.inf\n","    else:\n","        h0, ok = theta\n","        if 0. <= h0 <= 150. and -2. <= ok <= 2.:\n","            return 0.0\n","        else:\n","            return -np.inf\n","\n","#create a time-delay distance list\n","def get_ddt_list(zlens, zsource, z_step, Ez_gp, h0, ok):\n","    ddt_list = []\n","    for zl, zs in zip(zlens, zsource):\n","        ddt_list.append(get_model_indep_dist_ddt(zl, zs, z_step, Ez_gp, h0, ok))\n","    return np.array(ddt_list)\n","\n","#use a chi-square likelihood function\n","def log_likelihood(theta, zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp):\n","    if use_SNe:\n","        h0, ok, Mb = theta\n","    else:\n","        h0, ok = theta\n","    chi_sq = 0\n","    if use_Lens:\n","        ddt_list = get_ddt_list(zlens, zsource, z_step, Ez_gp, h0, ok)\n","        if np.all(ddt_list >= 0):\n","            chi_sq += np.sum((ddt_list - ddt_mock) ** 2 / (ddt_list * ddt_err) ** 2)\n","        else:\n","            return -np.inf\n","    if use_SNe:\n","        z_list_dl = list(zcmb)\n","        dl = np.zeros(len(zcmb))\n","        for z in zcmb:\n","            dl[z_list_dl.index(z)] = get_model_indep_dist_dl(z, z_step, Ez_gp, h0, ok)\n","        if np.all(dl >=0):\n","            mb = 5*np.log10(dl)+25+Mb\n","            del_m = mb_mock - mb\n","            chi_sq += np.dot(del_m.T, np.dot(C_inv, del_m))\n","        else:\n","            return -np.inf\n","    return -0.5 * chi_sq\n","\n","def log_probability(theta, zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp):\n","    \"\"\"\n","    theta: list of floats, folded cosmological parameters.\n","    zlens: array of z at lens\n","    zsource: array of z at source\n","    ddt_err: array of uncertainty of time-delay distance\n","    zcmb: array of z of cmb, obtained for SNe data\n","    C_inv: covariance matrix indicating uncertainty of SNe data\n","    z_step: float, the baseline step for integrating\n","    Ez_gp: array of normalised Hubble parameter from GP interpolation\n","    \"\"\"\n","    lp = log_prior(theta)\n","    if not np.isfinite(lp):\n","        return -np.inf\n","    return lp + log_likelihood(theta, zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp)\n","\n","\n","\"\"\"\n","Naming\n","\"\"\"\n","name = ''\n","if use_Lens:\n","    name += str(real_number)+'LSST'\n","if use_SNe:\n","    if name == '':\n","        name += 'Roman'\n","    else:\n","        name += '+Roman'\n","\n","\"\"\"\n","Maximum likelihood test\n","\"\"\"\n","if max_likelihood_test:\n","    nll = lambda *args: -log_likelihood(*args)\n","    if use_SNe:\n","        initial = np.array([75., 0.02, -19.])\n","        soln = minimize(nll, initial, args=(zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp))\n","        H0_ml, Ok_ml, Mb_ml = soln.x\n","        print(\"Maximum likelihood estimates:\")\n","        print(\"H0_ml = {0:.3f}\".format(H0_ml))\n","        print(\"Ok_ml = {0:.3f}\".format(Ok_ml))\n","        print(\"MB_ml = {0:.3f}\".format(Mb_ml))\n","    else:\n","        initial = np.array([75., 0.02, -19.])\n","        soln = minimize(nll, initial, args=(zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp))\n","        H0_ml, Ok_ml = soln.x\n","        print(\"Maximum likelihood estimates:\")\n","        print(\"H0_ml = {0:.3f}\".format(H0_ml))\n","        print(\"Ok_ml = {0:.3f}\".format(Ok_ml))\n","\n","print(name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0Ec1y2YWorB"},"outputs":[],"source":["\"\"\"\n","presettings for MCMC\n","\"\"\"\n","nwalkers = 16\n","nsamples = 1200\n","\n","if use_SNe:\n","    startpos = [70., 0.02, -19.]  # H0, Ok, MB\n","    labels = [\"$H_0$\", \"$Î©_{K}$\", \"M_{B}\"]\n","    parameters = [H0_mock, Ok0_mock, MB_mock]\n","else:\n","    startpos = [70., 0.02]  # H0, Ok\n","    labels = [\"$H_0$\", \"$\\Omega_{K}$\"]\n","    parameters = [H0_mock, Ok0_mock]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Fk974eyWorB"},"outputs":[],"source":["#MCMC\n","run_MCMC = True\n","save_MCMC = True\n","plot_MCMC = True\n","save_plot_MCMC = True\n","\n","if run_MCMC:\n","    pos = startpos + 1e-4 * np.random.randn(nwalkers, len(startpos))\n","    nwalkers, ndim = pos.shape\n","    display(\"Sampling cosmological parameters...\")\n","    sampler = emcee.EnsembleSampler(\n","        nwalkers, ndim, log_probability, args=[zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp]\n","    )\n","    sampler.run_mcmc(pos, nsamples, progress=True);\n","\n","if save_MCMC:\n","    samples = sampler.get_chain()\n","    flat_samples = sampler.get_chain(discard=200, thin=4, flat=True)\n","    sample_data = pd.DataFrame(flat_samples)\n","\n","    sample_data.to_csv(\n","        \"GP_samples/%s+HzGP_%ix%i.csv\"\n","        % (name, nwalkers, nsamples),\n","        index=False, header=labels\n","    )\n","#read data\n","if plot_MCMC:\n","    flat_samples = pd.read_csv(\"GP_samples/%s+HzGP_%ix%i.csv\"\n","                               % (name, nwalkers, nsamples), skiprows=1, header=None\n","                            )\n","    #plot\n","    fig = corner.corner(\n","        flat_samples, labels=labels, show_titles=True, quantiles=[0.16, 0.5, 0.84],\n","        title_fmt='.3f', use_math_text=True, truths=[H0_mock, Ok0_mock, MB_mock],\n","        plot_datapoints=False, smooth=0, levels=[0.68, 0.95], fill_contours=True,\n","        contour_kwargs={\"colors\": [\"black\"], \"linestyles\": [\"--\"], \"linewidths\": [2,0]},\n","        contourf_kwargs={\"colors\": [\"white\", \"grey\", \"black\"],\"alpha\":0.7}\n","    )\n","    fig.suptitle('%s samples, H(z) GP-fitted, mock=%s'\n","        % name, parameters), y=1.02, fontsize=16, fontweight='bold', ha='center')\n","    #save\n","    if save_plot_MCMC:\n","        fig.savefig(\"GP_plots/%s+HzGP_%ix%i_corner.png\"\n","                  % (name, nwalkers, nsamples)\n","                  , bbox_inches='tight'\n","                )\n","        display(\"Plot saved\")\n","    else:\n","        display(\"Plot not saved\")"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}