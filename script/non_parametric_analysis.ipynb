{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvZxM40nWoq-"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Yang Hu\n",
    "1. This file gives a script to constrain cosmological parameters (H0, Omega0, Omegak, MB, etc.)\n",
    "using strong gravitational lenses (lenses) and type Ia supernovae (SNe) with non-parametric analysis.\n",
    "2. We use baryon accoustic oscillation data (BAO) to obtain an interpolated curve for Hubble parameter Hz via\n",
    "Gaussian Process (GP). GP is carried out using george package.\n",
    "3. For lenses, we use simulated LSST data. For SNe, we use simulated Roman data. For BAO, we use simulated DESI data.\n",
    "4. Constraints on parameters are obtained via Markov Chain Monte Carlo (MCMC) using emcee package.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KKn0pRBWoq_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "standard imports for data analysis and astropy.cosmology to compute astrophysical quantities with ease\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emcee\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import simps\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import george\n",
    "from george import kernels\n",
    "from astropy.cosmology import FlatwCDM, LambdaCDM, wCDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8jmEfwyWoq_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load source data.\n",
    "\"\"\"\n",
    "\n",
    "#load and rename Lens data\n",
    "use_lens = 'Goldstein2019' # choose between Goldstein2019, Uniform or Arendse2023\n",
    "real_number = 1000 # equivalent number of lenses involved\n",
    "\n",
    "if use_lens == 'Goldstein2019':\n",
    "    data1 = pd.read_csv(\"../data/zlens_zsource_310LSSTLike_20.csv\",skiprows=1,header=None) # Goldstein et al. (2019)\n",
    "    zlens = np.array(data1[0])\n",
    "    zsource = np.array(data1[1])\n",
    "    ddt_err = np.array(data1[2])*np.sqrt(310/1000) # To estimate the uncertainty for 1000 lenses, we apply a factor of sqrt(N).\n",
    "elif use_lens == 'Uniform':\n",
    "    data1 = pd.read_csv(\"../data/uniform_1000LSSTLike_20.csv\",skiprows=1,header=None)\n",
    "    zlens = np.array(data1[0])\n",
    "    zsource = np.array(data1[1])\n",
    "    ddt_err = np.array(data1[2])\n",
    "elif use_lens == 'Arendse2023':\n",
    "    data1 = pd.read_csv(\"../data/Arendse23_redshifts_20.csv\",skiprows=1,header=None) # Goldstein et al. (2019)\n",
    "    zlens = np.array(data1[1])\n",
    "    zsource = np.array(data1[0])\n",
    "    ddt_err = np.array(data1[2])\n",
    "else:\n",
    "    print('Lens not defined')\n",
    "\n",
    "\n",
    "#load and rename SNe data\n",
    "data2 = pd.read_csv(\"../data/lcparam_WFIRST_G10.txt\", delimiter=' ', skiprows=1, header=None)\n",
    "data3 = pd.read_csv(\"../data/syscov_WFIRST.txt\", delimiter=' ', skiprows=0, header=None)\n",
    "zcmb = data2[1]\n",
    "\n",
    "#for a measure of the uncertainty of SNe measurement, we need the covariance matrix in the following way\n",
    "m_err = data2[5]\n",
    "sys_err = np.array(data3)\n",
    "D_stat = np.diag(m_err**2)\n",
    "C_sys = sys_err.reshape((len(data2), len(data2)))\n",
    "C = D_stat + C_sys\n",
    "C_inv = np.linalg.inv(C)\n",
    "\n",
    "#load and rename BAO data\n",
    "data4 = pd.read_csv(\"../data/DESI_HZ_error.txt\", delimiter=' ', skiprows=1, header=None) \n",
    "zBAO = data4[0]\n",
    "sigHz = data4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-DQXJbiWorA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Although this is a non-parametric approach, we still need to set a mock universe and generate the \"true value\" of parameters which are then\n",
    "used to compute the difference between true and measured (simulated) values which in turn are used to get\n",
    "the constraints of parameters.\n",
    "\"\"\"\n",
    "H0_mock, Om0_mock, Ok0_mock, w_mock, M_mock = 72, 0.3, 0.00, -1, -19.2\n",
    "cosmo_mock = wCDM(H0=H0_mock, Om0=Om0_mock, Ode0=1.-Om0_mock-Ok0_mock, w0=w_mock)\n",
    "\n",
    "#compute mock time-delay distance for lenses\n",
    "dd_mock = cosmo_mock.angular_diameter_distance(z=zlens)\n",
    "ds_mock = cosmo_mock.angular_diameter_distance(z=zsource)\n",
    "dds_mock = cosmo_mock.angular_diameter_distance_z1z2(z1=zlens, z2=zsource)\n",
    "ddt_mock = (1. + zlens) * dd_mock * ds_mock / dds_mock\n",
    "\n",
    "#compute mock luminosity distance for SNe\n",
    "dl_mock = cosmo_mock.luminosity_distance(z=zcmb)\n",
    "m_mock = 5*np.log10(np.array(dl_mock))+25+M_mock\n",
    "\n",
    "#compute mock Hz from BAO data\n",
    "Hz_mock = cosmo_mock.H(z=zBAO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get a starting point of GP hyperparameters from BAO data using george package.\n",
    "Constraints are obtained by MCMC and here we define the relevant prior and likelihood functions.\n",
    "\"\"\"\n",
    "\n",
    "#compute a rough interpolation as starting values for MCMC\n",
    "gp = george.GP(1*np.var(Hz_mock)*kernels.ExpSquaredKernel(1), fit_kernel=True,\n",
    "               mean=np.mean(Hz_mock), white_noise=None)\n",
    "print(gp.parameter_names)\n",
    "gp.compute(zBAO, sigHz)\n",
    "\n",
    "#defining mcmc functions\n",
    "def lnprob(p):\n",
    "    if np.any((-100 > p[1:]) + (p[1:] > 100)):\n",
    "        return -np.inf\n",
    "    gp.set_parameter_vector(p)\n",
    "    return gp.log_likelihood(Hz_mock, quiet=True)\n",
    "labels = [\"$α$\", \"$l$\"]\n",
    "\n",
    "#Set up the sampler.\n",
    "nwalkers, nsamples, ndim = 32, 8000, len(gp)\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob)\n",
    "\n",
    "#Initialize the walkers.\n",
    "p0 = gp.get_parameter_vector() + 1e-4 * np.random.randn(nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run MCMC on hyperparameters using emcee package. After loading a sample file, we can plot a corner plot showing how well constraints are placed on each interested\n",
    "hyperparamters by the data.\n",
    "\"\"\"\n",
    "\n",
    "run_mcmc = False\n",
    "save_mcmc = False\n",
    "plot_mcmc = False\n",
    "save_plot_mcmc = False\n",
    "\n",
    "if run_mcmc:\n",
    "    print(\"Sampling...\")\n",
    "    sampler.run_mcmc(p0, nsamples, progress=True);\n",
    "\n",
    "if save_mcmc:\n",
    "    samples = sampler.get_chain()\n",
    "    flat_samples = sampler.get_chain(discard=500, thin=4, flat=True)\n",
    "    sample_data = pd.DataFrame(flat_samples)\n",
    "    sample_data.to_csv(\n",
    "    \"../sample/amp_ls_%ix%i.csv\"\n",
    "    % (nwalkers, nsamples),\n",
    "    index=False, header=None\n",
    ")\n",
    "\n",
    "if plot_mcmc:\n",
    "    flat_samples = pd.read_csv(\"../sample/amp_ls_%ix%i.csv\" % (nwalkers, nsamples), skiprows=1, header=None)\n",
    "    fig = corner.corner(\n",
    "        flat_samples, labels=labels,show_titles=True, quantiles=[0.16, 0.5, 0.84],\n",
    "        title_fmt='.3f', use_math_text=True, plot_datapoints=False, levels=[0.68, 0.95], fill_contours=True,\n",
    "        contour_kwargs={\"colors\": [\"black\"], \"linestyles\": [\"--\"], \"linewidths\": [2,0]},\n",
    "        contourf_kwargs={\"colors\": [\"white\", \"grey\", \"black\"],\"alpha\":0.7}\n",
    "    )\n",
    "    fig.suptitle(\"Hyperparameters, %ix%i\" % (nwalkers, nsamples), y=1.02,\n",
    "                 fontsize=16, fontweight='bold', ha='center')\n",
    "    if save_plot_mcmc:\n",
    "        fig.savefig(\"../plot/amp_ls_corner_%ix%i.png\" % (nwalkers, nsamples), bbox_inches='tight')\n",
    "        display(\"Plot saved\")\n",
    "    else:\n",
    "        display(\"Plot not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plot interpolated curve with optimal hyperparameters for testing\n",
    "\"\"\"\n",
    "\n",
    "save_figure = True\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "#here we need to replace the two numercial values by whatever values we get from MCMC\n",
    "amp, ls = 10.163, 1.924\n",
    "gp_optimal = george.GP(amp*np.var(Hz_mock)*kernels.ExpSquaredKernel(ls), fit_kernel=True,\n",
    "               mean=np.mean(Hz_mock), white_noise=None)\n",
    "gp_optimal.compute(zBAO, sigHz)\n",
    "\n",
    "z_pred = np.linspace(0., max(zBAO), 500)\n",
    "pred, pred_var = gp_optimal.predict(Hz_mock, z_pred, return_var=True)\n",
    "\n",
    "plt.rc('font', family='serif', size=10)\n",
    "plt.fill_between(z_pred, pred - 2 * np.sqrt(pred_var), pred + 2 * np.sqrt(pred_var),\n",
    "                 color=\"k\", alpha=0.2, label='2σ interval')\n",
    "plt.plot(z_pred, pred, \"k\", lw=1.5, alpha=0.5, label='GP predictive mean')\n",
    "plt.errorbar(zBAO, Hz_mock, yerr=sigHz, fmt=\".k\", markersize=1, lw=1, label='BAO data')\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.xticks([0.0, 0.4, 0.8, 1.2, 1.6])\n",
    "plt.yticks([60,100,140,180])\n",
    "plt.xlabel(\"$z_{BAO}$\",fontsize=16)\n",
    "plt.ylabel(\"$H(z)$\",fontsize=16)\n",
    "plt.title(\"$H(z)$ VS $z_{BAO}$\", fontsize=16)\n",
    "plt.legend(fontsize=14)  # Add legend\n",
    "plt.tight_layout()\n",
    "if save_figure:\n",
    "    plt.savefig(\"../plot/optimal_hyperparameters.png\", bbox_inches='tight',dpi=512)\n",
    "    display(\"Plot saved\")\n",
    "else:\n",
    "    display(\"Plot not saved\")\n",
    "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkvLBLTgWorA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GP interpolate Hz from BAO data using george package\n",
    "\"\"\"\n",
    "\n",
    "#function to get GP interpolation\n",
    "def get_gp_interp(zBAO, Hz_mock, sigHz):\n",
    "    \"\"\"\n",
    "    Compute the GP interpolation with the error covariance matrix\n",
    "    TO DO: Marginalise over kernel hyperparameters\n",
    "    zBAO: array of z from BAO\n",
    "    Hz_mock: array of Hz from BAO\n",
    "    sigHz: array of uncertainty of Hz\n",
    "    \"\"\"\n",
    "    #the 2 optical numerical values of hyperparameters are obtained via MCMC in a seperate script:\n",
    "    #\"HzGP_constraint.ipynb\"\n",
    "    #you can also find the values in \"amp_ls_corner_32x8000.png\"\n",
    "    gp = george.GP(10.163*np.var(Hz_mock)*kernels.ExpSquaredKernel(1.924),\n",
    "               mean=np.mean(Hz_mock), white_noise=None)\n",
    "    Hz = Hz_mock\n",
    "    Hz_err = sigHz\n",
    "    #define the redshift region for predicting the GP fit\n",
    "    z_step = np.linspace(0., max(zBAO), 4000)\n",
    "    gp.compute(zBAO, Hz_err)\n",
    "    Hz_gp = gp.predict(Hz, z_step, return_cov=False)\n",
    "    return z_step, Hz_gp\n",
    "\n",
    "z_step, Hz_gp = get_gp_interp(zBAO, Hz_mock, sigHz)\n",
    "#normalise the E(z)\n",
    "Ez_gp = Hz_gp/Hz_gp[0]\n",
    "#this is the normalised Hz interpolation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJTDB_Y6WorA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We want to get cosmological distances in likelihood function in a non-parametric way.\n",
    "\"\"\"\n",
    "\n",
    "c = 299792.458 #in km/s\n",
    "\n",
    "#function to get time-delay distance in a non-parametric way\n",
    "def get_model_indep_dist_ddt(zl, zs, z_step, Ez_gp, h0, ok):\n",
    "    \"\"\"\n",
    "    Doesn't account for errors in the GP fit as of now\n",
    "    zl: float of z at lenses\n",
    "    zs: float of z at source to integrate till\n",
    "    z_step: float, the baseline step for integrating\n",
    "    Ez_gp: array of normalised Hubble parameter from GP interpolation\n",
    "    h0: float, a value of Hubble's constant\n",
    "    ok: float, a value of curvature density parameter\n",
    "    \"\"\"\n",
    "    cond_l = z_step <= zl\n",
    "    cond_s = z_step <= zs\n",
    "    Ez_gp_l = Ez_gp[cond_l]\n",
    "    Ez_gp_s = Ez_gp[cond_s]\n",
    "    dh = c/h0\n",
    "\n",
    "    int_comov_l = simps(1/Ez_gp_l, z_step[cond_l])\n",
    "    int_comov_s = simps(1/Ez_gp_s, z_step[cond_s])\n",
    "\n",
    "    if ok < 0.:\n",
    "        dm_l = dh/np.sqrt(abs(ok))*np.sin(np.sqrt(abs(ok))*int_comov_l)\n",
    "        dm_s = dh/np.sqrt(abs(ok))*np.sin(np.sqrt(abs(ok))*int_comov_s)\n",
    "    elif ok == 0.:\n",
    "        dm_l = dh*int_comov_l\n",
    "        dm_s = dh*int_comov_s\n",
    "    elif ok > 0.:\n",
    "        dm_l = dh/np.sqrt(abs(ok))*np.sinh(np.sqrt(abs(ok))*int_comov_l)\n",
    "        dm_s = dh/np.sqrt(abs(ok))*np.sinh(np.sqrt(abs(ok))*int_comov_s)\n",
    "\n",
    "    da_l = dm_l/(1+zl)\n",
    "    da_s = dm_s/(1+zs)\n",
    "    da_ls = (1/(1+zs) *\n",
    "             (dm_s * np.sqrt(1 + ok * (dm_l / dh)**2) - dm_l * np.sqrt(1 + ok * (dm_s / dh)**2)))\n",
    "\n",
    "    ddt = (1 + zl) * da_l * da_s / da_ls\n",
    "    return ddt\n",
    "\n",
    "#function to get luminosity distance in a non-parametric way\n",
    "def get_model_indep_dist_dl(z, z_step, Ez_gp, h0, ok):\n",
    "    \"\"\"\n",
    "    Doesn't account for errors in the GP fit as of now\n",
    "    z: float of z from SNe\n",
    "    z_step: float, the baseline step for integrating\n",
    "    Ez_gp: array of normalised Hubble parameter from GP interpolation\n",
    "    h0: float, a value of Hubble's constant\n",
    "    ok: float, a value of curvature density parameter\n",
    "    \"\"\"\n",
    "    cond = z_step <= z\n",
    "    Ez_gp = Ez_gp[cond]\n",
    "    if ok < 0.:\n",
    "        int_comov = simps(1/Ez_gp, z_step[cond])\n",
    "        comov_curv = np.sqrt(abs(ok)) * int_comov\n",
    "        dl_int = c*np.sin(comov_curv) * (1+z) / (np.sqrt(abs(ok)))\n",
    "    elif ok > 0.:\n",
    "        int_comov = simps(1/Ez_gp, z_step[cond])\n",
    "        comov_curv = np.sqrt(abs(ok)) * int_comov\n",
    "        dl_int = c*np.sinh(comov_curv) * (1+z) / (np.sqrt(abs(ok)))\n",
    "    elif ok == 0.:\n",
    "        int_comov = simps(1/Ez_gp, z_step[cond])\n",
    "        comov_curv = int_comov\n",
    "        dl_int = c*comov_curv * (1+z)\n",
    "    dl_int /= h0\n",
    "    return dl_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBr2OMdkWorB"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell defines the loss function of MCMC\n",
    "Constraints are obtained by MCMC and here we define the relevant prior and likelihood functions\n",
    "\"\"\"\n",
    "\n",
    "# select which probes to use; must at least select one\n",
    "use_Lens = False\n",
    "use_SNe = True\n",
    "\n",
    "max_likelihood_test = True\n",
    "\n",
    "#use uniform priors for all parameters\n",
    "def log_prior(theta):\n",
    "    \"\"\"\n",
    "    theta: list of floats, folded cosmological parameters.\n",
    "    \"\"\"\n",
    "    if use_SNe:\n",
    "        h0, ok, M = theta\n",
    "        if 0. <= h0 <= 150. and -2. <= ok <= 2. and -25. <= M <= -15.:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return -np.inf\n",
    "    else:\n",
    "        h0, ok = theta\n",
    "        if 0. <= h0 <= 150. and -2. <= ok <= 2.:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return -np.inf\n",
    "\n",
    "#create a time-delay distance list\n",
    "def get_ddt_list(zlens, zsource, z_step, Ez_gp, h0, ok):\n",
    "    ddt_list = []\n",
    "    for zl, zs in zip(zlens, zsource):\n",
    "        ddt_list.append(get_model_indep_dist_ddt(zl, zs, z_step, Ez_gp, h0, ok))\n",
    "    return np.array(ddt_list)\n",
    "\n",
    "#use a chi-square likelihood function\n",
    "def log_likelihood(theta, zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp):\n",
    "    if use_SNe:\n",
    "        h0, ok, M = theta\n",
    "    else:\n",
    "        h0, ok = theta\n",
    "    chi_sq = 0\n",
    "    if use_Lens:\n",
    "        ddt_list = get_ddt_list(zlens, zsource, z_step, Ez_gp, h0, ok)\n",
    "        if np.all(ddt_list >= 0):\n",
    "            chi_sq += np.sum((ddt_list - ddt_mock.value) ** 2 / (ddt_list * ddt_err) ** 2)\n",
    "        else:\n",
    "            return -np.inf\n",
    "    if use_SNe:\n",
    "        z_list_dl = list(zcmb)\n",
    "        dl = np.zeros(len(zcmb))\n",
    "        for z in zcmb:\n",
    "            dl[z_list_dl.index(z)] = get_model_indep_dist_dl(z, z_step, Ez_gp, h0, ok)\n",
    "        if np.all(dl >=0):\n",
    "            m = 5*np.log10(dl)+25+M\n",
    "            del_m = m_mock - m\n",
    "            chi_sq += np.dot(del_m.T, np.dot(C_inv, del_m))\n",
    "        else:\n",
    "            return -np.inf\n",
    "    return -0.5 * chi_sq\n",
    "\n",
    "def log_probability(theta, zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp):\n",
    "    \"\"\"\n",
    "    theta: list of floats, folded cosmological parameters.\n",
    "    zlens: array of z at lens\n",
    "    zsource: array of z at source\n",
    "    ddt_err: array of uncertainty of time-delay distance\n",
    "    zcmb: array of z of cmb, obtained for SNe data\n",
    "    C_inv: covariance matrix indicating uncertainty of SNe data\n",
    "    z_step: float, the baseline step for integrating\n",
    "    Ez_gp: array of normalised Hubble parameter from GP interpolation\n",
    "    \"\"\"\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Naming\n",
    "\"\"\"\n",
    "name = ''\n",
    "if use_Lens:\n",
    "    if use_lens =='Goldstein2019':\n",
    "        name += 'LSST'\n",
    "    elif use_lens =='Uniform':\n",
    "        name += 'LSSTu'\n",
    "    else:\n",
    "        name += 'LSSTa'\n",
    "if use_SNe:\n",
    "    if name == '':\n",
    "        name += 'Roman'\n",
    "    else:\n",
    "        name += '+Roman'\n",
    "name += '+HzGP'\n",
    "\n",
    "\"\"\"\n",
    "Maximum likelihood test\n",
    "\"\"\"\n",
    "if max_likelihood_test:\n",
    "    nll = lambda *args: -log_likelihood(*args)\n",
    "    if use_SNe:\n",
    "        initial = np.array([75., 0.02, -19.])\n",
    "        soln = minimize(nll, initial, args=(zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp))\n",
    "        H0_ml, Ok_ml, M_ml = soln.x\n",
    "        print(\"Maximum likelihood estimates:\")\n",
    "        print(\"H0_ml = {0:.3f}\".format(H0_ml))\n",
    "        print(\"Ok_ml = {0:.3f}\".format(Ok_ml))\n",
    "        print(\"M_ml = {0:.3f}\".format(M_ml))\n",
    "    else:\n",
    "        initial = np.array([75., 0.02])\n",
    "        soln = minimize(nll, initial, args=(zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp))\n",
    "        H0_ml, Ok_ml = soln.x\n",
    "        print(\"Maximum likelihood estimates:\")\n",
    "        print(\"H0_ml = {0:.3f}\".format(H0_ml))\n",
    "        print(\"Ok_ml = {0:.3f}\".format(Ok_ml))\n",
    "\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0Ec1y2YWorB"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "presettings for MCMC\n",
    "\"\"\"\n",
    "nwalkers = 16\n",
    "nsamples = 1200\n",
    "\n",
    "if use_SNe:\n",
    "    startpos = [70., 0.02, -19.]  # H0, Ok, M\n",
    "    labels = [\"$H_0$\", \"$Ω_{K}$\", \"M\"]\n",
    "    parameters = [H0_mock, Ok0_mock, M_mock]\n",
    "else:\n",
    "    startpos = [70., 0.02]  # H0, Ok\n",
    "    labels = [\"$H_0$\", \"$\\Omega_{K}$\"]\n",
    "    parameters = [H0_mock, Ok0_mock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fk974eyWorB"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MCMC\n",
    "\"\"\"\n",
    "# Select whether you want to run and save MCMC, plot and save \n",
    "run_MCMC = True\n",
    "save_MCMC = True\n",
    "plot_MCMC = True\n",
    "save_plot_MCMC = True\n",
    "\n",
    "if run_MCMC:\n",
    "    pos = startpos + 1e-4 * np.random.randn(nwalkers, len(startpos))\n",
    "    nwalkers, ndim = pos.shape\n",
    "    display(\"Sampling cosmological parameters with %s...\" % name)\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        nwalkers, ndim, log_probability, args=[zlens, zsource, ddt_err, zcmb, C_inv, z_step, Ez_gp]\n",
    "    )\n",
    "    sampler.run_mcmc(pos, nsamples, progress=True);\n",
    "\n",
    "if save_MCMC:\n",
    "    samples = sampler.get_chain()\n",
    "    flat_samples = sampler.get_chain(discard=200, thin=4, flat=True)\n",
    "    sample_data = pd.DataFrame(flat_samples)\n",
    "\n",
    "    sample_data.to_csv(\n",
    "        \"../sample/%s_%ix%i.csv\"\n",
    "        % (name, nwalkers, nsamples),\n",
    "        index=False, header=labels\n",
    "    )\n",
    "#read data\n",
    "if plot_MCMC:\n",
    "    flat_samples = pd.read_csv(\"../sample/%s_%ix%i.csv\"\n",
    "                               % (name, nwalkers, nsamples), skiprows=1, header=None\n",
    "                            )\n",
    "    #plot\n",
    "    fig = corner.corner(\n",
    "        flat_samples, labels=labels, show_titles=True, quantiles=[0.16, 0.5, 0.84],\n",
    "        title_fmt='.3f', use_math_text=True, truths=[H0_mock, Ok0_mock, M_mock],\n",
    "        plot_datapoints=False, smooth=0, levels=[0.68, 0.95], fill_contours=True,\n",
    "        contour_kwargs={\"colors\": [\"black\"], \"linestyles\": [\"--\"], \"linewidths\": [2,0]},\n",
    "        contourf_kwargs={\"colors\": [\"white\", \"grey\", \"black\"],\"alpha\":0.7}\n",
    "    )\n",
    "    fig.suptitle('%s samples, H(z) GP-fitted, mock=%s'\n",
    "        % (name, parameters), y=1.02, fontsize=16, fontweight='bold', ha='center')\n",
    "    #save\n",
    "    if save_plot_MCMC:\n",
    "        fig.savefig(\"../plot/%s_%ix%i_corner.png\"\n",
    "                  % (name, nwalkers, nsamples)\n",
    "                  , bbox_inches='tight'\n",
    "                   )\n",
    "        display(\"Plot saved\")\n",
    "    else:\n",
    "        display(\"Plot not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
